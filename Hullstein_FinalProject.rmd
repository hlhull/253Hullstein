---
title: "Hullstein_FinalProject"
author: "Eleanor Wettstein"
date: "4/21/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE)
```

```{r}
#plotting and exploring
library(tidyverse) #for plotting and summarizing
library(vip) #for importance plots
library(pROC) #for ROC curves
library(plotROC) #for plotting ROC curves

#making things look nice
library(knitr) #for nice tables
library(scales) #for nice labels on graphs
library(gridExtra) #for arranging plots
library(broom) #for nice model output
library(janitor) #for nice names

#data
library(ISLR) #for data

#modeling
library(rsample) #for splitting data
library(caret) #for modeling
library(leaps) #for variable selection
library(glmnet) #for LASSO
library(rpart) #for decision trees
library(randomForest) #for bagging and random forests

library(e1071)

theme_set(theme_minimal())
```

# Introduction

```{r}
# read in data, replace ? with NA
diabetes <- read_csv("diabetic_data.csv", na = "?")

# remove people who died who were discharged to hospice
diabetes <- diabetes[!(diabetes$discharge_disposition_id==19 |
                         diabetes$discharge_disposition_id==21 |
                         diabetes$discharge_disposition_id==13 |
                         diabetes$discharge_disposition_id==14 |
                         diabetes$discharge_disposition_id==11 |
                         diabetes$discharge_disposition_id==20),]

# make classifications categories
diabetes$discharge_disposition_id <- as.factor(diabetes$discharge_disposition_id)
diabetes$admission_type_id <- as.factor(diabetes$admission_type_id)
diabetes$admission_source_id <- as.factor(diabetes$admission_source_id)

# lump discharge into 4 categories (home, skilled nursing facility, home health service, other)
diabetes <- diabetes %>%
  mutate(discharge_disposition_id = fct_lump(discharge_disposition_id,n=3))

# lump admission source into 3 categories (physician, emergency room, other)
diabetes <- diabetes %>%
  mutate(admission_source_id = fct_lump(admission_source_id,n=2))

# lump admission type into 4 categories (Emergency, Urgent, Elective, other)
diabetes <- diabetes %>%
  mutate(admission_type_id = fct_lump(admission_type_id,n=3))

# combine youngest ages
diabetes$age <- fct_collapse(diabetes$age, "[0-30)"= c("[0-10)","[10-20)","[20-30)"))

# remove medicines without 2+ categories, categories with lots missing, and other variables
drop <- c("acetohexamide", "tolbutamide", "troglitazone", "examide", "citoglipton", "glyburide-metformin", "glipizide-metformin", "glimepiride-pioglitazone", "metformin-rosiglitazone", "metformin-pioglitazone", "weight", "medical_specialty", "payer_code", "encounter_id", "patient_nbr", "diag_1", "diag_2", "diag_3")
diabetes <- diabetes[, !(names(diabetes) %in% drop)]

# make binomial readmitted variable
diabetes <- diabetes %>% 
  mutate(readmitted30 = ifelse(readmitted == "<30", 'true', 'false'))
diabetes$readmitted30 <- as.factor(diabetes$readmitted30)

```

```{r}
# split into test and train
set.seed(253) 
diab_split <- initial_split(diabetes, prop = .7, 
                             strata = readmitted30)
diab_train <- training(diab_split)
diab_test <- testing(diab_split)
```

Background: It is essential to provide the proper care for patients with diabetes, especially those that are hospitalized, in order to achieve the optimum outcome in terms of mortality and overall level of health and well-being. One way to approach this is to keep track of what factors contribute to a diabetes patient being readmitted to a hospital following previous treatment.

Data: We used a clinical database that contains information about patients who sought or required medical care due to diabetes. This dataset included variables such as demographic descriptors, type and severity of diabetes, and type of medical visit. 

Research question: What variables can be used to best predict whether or not a diabetes patient will be readmitted to a medical facility within 30 days of previous treatment. 

Plan of action: Using modeling techniques that we have learned in class, we plan to apply various models to the dataset (such as logistic regression and lasso) in an effort to determine which predictors are most useful in assessing whether a patient will be readmitted to a hospital.

Data cleaning: We performed some data cleaning before testing the models.

* If predictor variables had a few terms that constituted the majority of observations, we grouped the more sparse terms into an “other” category (or an equivalent grouping that made sense). This was done for `discharge_disposition_id`, `admission_type_id`, `admission_source_id`, and `age`.

* We removed observations corresponding to patients who died or were placed on hospice. While they technically were not readmitted to a hospital within 30 days, they are not healthy and would skew that data.

* We removed variables that had majority missing values or for which most of the observations had the same term. This resulted in the dropping of `weight`, several medications, and a few other variables.

* Finally, we created our response variable, `readmitted30`, to be a binomial variable to allow for logistic regression analysis. This variable is `true` if the patient is readmitted into the hospital within 30 days of being discharged, and `false` otherwise.


The following is a graph summarizing the response variable, `readmitted30`.

```{r}
ggplot(diabetes, aes(x=readmitted30)) +
  geom_bar()
```

As you can see, most patients were not readmitted within 30 days. Because of this imbalance, we had to down sample our models so that they didn't end up reflecting the No Information Rate. Instead, we would rather have more false positives, so that doctors are aware of patients who may be at a higher risk of being readmitted.

# Exploratory Analysis

```{r, results = 'hide'}
# table(diab_train$readmitted30) %>% prop.table()
# dim(diab_train)
# glimpse(diab_train)
```


```{r, results = 'hide'}
# ggplot(diabetes, aes(x=readmitted30)) +
#   geom_bar()
# 
# ggplot(diabetes, aes(x=num_lab_procedures, fill = readmitted30)) +
#   geom_histogram()
```

```{r, results = 'hide'}

# ggplot(diabetes, aes(x=age, fill=readmitted30)) +
#   geom_bar(position="fill")
# 
# diabetes %>% 
#   ggplot(aes(x = age, fill = readmitted30)) +
#   geom_bar(position = "fill")
# 
# diabetes %>% 
#   ggplot(aes(x = readmitted30, fill = age)) +
#   geom_bar(position = "fill")
# 
# diabetes %>% 
#   ggplot(aes(x = readmitted30, fill = A1Cresult)) +
#   geom_bar(position = "fill")
# 
# diabetes %>% 
#   ggplot(aes(x = readmitted30, fill = factor(time_in_hospital))) +
#   geom_bar(position = "fill")
# diabetes %>% 
#   ggplot(aes(x = factor(time_in_hospital), fill = readmitted30)) +
#   geom_bar(position = "fill")
# 
# ggplot(diabetes, aes(x=time_in_hospital, fill=readmitted30)) +
#   geom_density(alpha=.5)
```

```{r}
# combine infrequent #s in top range
diabetes$number_inpatient_graph <- as.factor(diabetes$number_inpatient)
diabetes$number_inpatient_graph <- fct_collapse(diabetes$number_inpatient_graph, "11+"= c("11","12","13", "14", "15", "16", "17","18","19","20","21"))

diabetes %>% 
  ggplot(aes(x = number_inpatient_graph, fill = readmitted30)) +
  geom_bar(position = "fill") +
  labs(x = "number_inpatient")
```

This shows the number of inpatient visits the patient had the year before the hospitalization. This becomes one of the most important variables in the model because, as you can see in the graph, as the number of inpatient visits the patient had increases, the likelihood that they will be readmitted also increases.

```{r}
diabetes %>% 
  ggplot(aes(x = discharge_disposition_id, fill = readmitted30)) +
  geom_bar(position = "fill")
```

The `discharge_disposition_id` became another important variable. This variable describes where the patient went after they were released from the hosptial. '1' means they went home, which you can see has the smallest proportion of readmitted patients. '3' means they went to a skilled nursing facility and '6' means they went home, but also had a health service at home to assist them. 

```{r}
# combine infrequent #s in top range
diabetes$number_diagnoses_graph <- as.factor(diabetes$number_diagnoses)
diabetes$number_diagnoses_graph <- fct_collapse(diabetes$number_diagnoses_graph, "9+"= c("9", "10", "11","12","13", "14", "15", "16"))

diabetes %>% 
  ggplot(aes(x = number_diagnoses_graph, fill = readmitted30)) +
  geom_bar(position = "fill") +
  labs(x = "number_diagnoses")
```

Finally, `number_diagnoses` was one last key variable. It describes how many diagnoses were entered into the patients record during the hospital visit. As the number of diagnoses increases, so does the proportion of patients readmitted.

# Models


## Logistic Regression 

```{r, results = 'hide'}
# other_vars <- c('race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id','time_in_hospital','num_lab_procedures','num_procedures', 'num_medications', 'readmitted30')
# other_subset <- diab_train[other_vars]
# 
# 
# med_vars <- c('metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide','glyburide','pioglitazone','rosiglitazone','acarbose','miglitol','tolazamide',
#   'insulin', 'readmitted30')
# med_subset <- diab_train[med_vars]
# 
# med_subsetS <- med_subset %>%
#   slice(1:3000)
```


```{r, results = 'hide'}
# # Set the seed
# set.seed(253)
# 
# # Run the model
# diabO_logAll <- train(
#     readmitted30 ~ .,
#     data = other_subset, 
#     method = "glm",
#     family = "binomial",
#     trControl = trainControl(method = "cv", number = 5, sampling = "down"),
#     metric = "Accuracy",
#     na.action = na.omit
# )
```

```{r, results = 'hide'}
# summary(diabO_logAll$finalModel) %>% 
#   coef() %>% 
#   tidy() %>% 
#   select(`.rownames`, Estimate) %>% 
#   mutate(exp_coef = exp(Estimate))
# diabO_logAll$results$Accuracy

#confusionMatrix(data = predict(diabO_logAll, type = "raw"), #predictions
#                reference = other_subset$readmitted30, #actuals
#                positive = "true") 
```

```{r, echo = TRUE}
# Set the seed
set.seed(253)

# Run the model
diab_logAll <- train(
    readmitted30 ~ .,
    data = diab_train %>% select(-readmitted), 
    method = "glm",
    family = "binomial",
    trControl = trainControl(method = "cv", number = 5, sampling = "down"),
    metric = "Accuracy",
    na.action = na.omit
)
```

```{r}
diab_logAll$results$Accuracy

confusionMatrix(data = predict(diab_logAll, type = "raw", na.action = na.pass), #predictions
                reference = na.omit(diab_train)$readmitted30)#, #actuals
```

## Lasso
```{r, results = 'hide'}
# set.seed(253)
# 
# diabO_lasso <- train(
#     readmitted30 ~ .,
#     data = other_subset,
#     method = "glmnet",
#     family = "binomial",
#     trControl = trainControl(method = "cv", number = 5, sampling = "down"),
#     tuneGrid = data.frame(alpha = 1, 
#                           lambda = 10^seq(-5, -1, length = 100)),
#     metric = "Accuracy",
#     na.action = na.omit
# )
# 
# diabO_lasso$bestTune
```
```{r, results = 'hide'}
# diabO_lasso$results %>% 
#   ggplot(aes(x = lambda, y = Accuracy)) +
#   geom_line() +
#   geom_point() +
#   scale_x_log10()
```


```{r, echo = TRUE}
set.seed(253)

diab_lasso <- train(
    readmitted30 ~ .,
    data = diab_train %>% select(-readmitted),
    method = "glmnet",
    family = "binomial",
    trControl = trainControl(method = "cv", number = 5, sampling = "down"),
    tuneGrid = data.frame(alpha = 1, 
                          lambda = 10^seq(-4, -1, length = 100)),
    metric = "Accuracy",
    na.action = na.omit
)

```

```{r}
diab_lasso$results %>% 
  ggplot(aes(x = lambda, y = Accuracy)) +
  geom_line() +
  geom_point() +
  scale_x_log10()

coefficients(diab_lasso$finalModel, s = diab_lasso$bestTune$lambda)

confusionMatrix(data = predict(diab_lasso, type = "raw", na.action = na.pass), #predictions
                reference = na.omit(diab_train)$readmitted30)#, #actuals
```

## Classification Tree
```{r, results = 'hide'}
# set.seed(253)
# 
# diabO_tree <- train(
#   readmitted30 ~ .,
#   data = other_subset,
#   method = "rpart",
#   tuneGrid = data.frame(cp = 10^seq(-4, -2 , 
#                                     length = 50)),
#   trControl = trainControl(method = "cv", number = 5, sampling = "down"),
#   metric = "Accuracy",
#   na.action = na.omit
# )
```

```{r, results = 'hide'}
# diabO_tree$bestTune
# diabO_tree
# 
# diabO_tree$results %>%
#   ggplot(aes(x = cp, y = Accuracy)) +
#   geom_line()+
#   geom_point()
```


```{r, echo = TRUE}
set.seed(253)

diab_tree <- train(
  readmitted30 ~ .,
  data = diab_train %>% select(-readmitted),
  method = "rpart",
  tuneGrid = data.frame(cp = 10^seq(-5, -2, # if you go out to -1 you see the no information rate
                                    length = 100)),
  trControl = trainControl(method = "cv", number = 5, sampling = "down"),
  metric = "Accuracy",
  na.action = na.omit
)
```

```{r}
diab_tree$results %>%
  ggplot(aes(x = cp, y = Accuracy)) +
  geom_line()+
  geom_point()

confusionMatrix(data = predict(diab_tree, type = "raw", na.action = na.pass), #predictions
                reference = na.omit(diab_train)$readmitted30)#, #actuals
```


## Random Forest

```{r, echo = TRUE}
set.seed(327)
diab_randf <- train(
  readmitted30 ~ .,
  data = diab_train %>% select(-readmitted), 
  method = "rf",
  metric = "Accuracy",
  trControl = trainControl(method = "oob", sampling = "down"),
  tuneGrid = data.frame(mtry = c(2,4,6,8,10,12)),
  ntree = 50, #number of trees used, default is 500
 importance = TRUE, #for importance plots later
  nodesize = 5, #this is the default terminal node size for regression trees. Could set larger for smaller trees.
 na.action = na.omit
)
```


```{r}
plot(diab_randf$finalModel)

diab_randf$results
```

```{r}
vip(diab_randf$finalModel)
```

We also plan on adding some discussion of each model.

# Evaluating the Models

Here we will compare the cross-validated / OOB accuracy of the models to each other and pick the best models to apply them to the test set to determine our final best model.

# Conclusion

We were not able to develop a model that yielded a better prediction of hospital readmittance than the NIR, which was 0.886. However, we created a model using the lasso technique with fairly high accuracy and fewer variables. A model with comparable accuracy and less predictor variables is still desirable because it is less complex and inaccessible to non-statisticians while still allowing doctors to make predictions about which diabetes patients should be more closely monitored based on their likelihood to be readmitted within 30 days. In particular, we found that a patient’s previous hospital admittance history (`number_inpatient`) and where they were discharged to (`discharge_disposition_id`) were key in predicting whether they’d be readmitted soon. Additionally, the number of diagnoses a patient had (`number_diagnoses`) was a key variable, possibly because it indicates other conditions and the severity of their diabetes. Interestingly, the medication(s) they were put on did not seem to have much of an impact on readmittance. We tried a few models on a subset of the data composed only of predictor variables that were diabetes medications. We expected medications to be relatively powerful predictors, but we were surprised to find that the best of these models only resulted in about 60% accuracy.





